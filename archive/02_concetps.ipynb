{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"SOME UNICODE text with special characters like aÌˆ oÌˆ uÌˆ some emojis ğŸ”¥ and rare unicode\"\n",
    "text_2 = \"simple text\"\n",
    "print(len(text), len(text_2))\n",
    "byte_tokens = list(text.encode('utf-8'))\n",
    "byte_tokens_2 = list(text_2.encode('utf-8'))\n",
    "print(len(byte_tokens), len(byte_tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_pairs(encoded_u8: list[int]) -> tuple[int, int]:\n",
    "    sample_txt_pair_stats = Counter()\n",
    "    for a, b in zip(encoded_u8, encoded_u8[1:]):\n",
    "        sample_txt_pair_stats[(a, b)] += 1\n",
    "    print(sample_txt_pair_stats.most_common(1)[0])\n",
    "    return sample_txt_pair_stats.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "def merge(encoded_u8: list[int], pair: tuple[int, int], new_char: int) -> list[int]:\n",
    "    n = 0\n",
    "    result = []\n",
    "    while n < len(encoded_u8):\n",
    "        if n < len(encoded_u8) - 1:\n",
    "            if (encoded_u8[n], encoded_u8[n + 1]) == pair:\n",
    "                result.append(new_char)\n",
    "                n += 2\n",
    "                continue\n",
    "        result.append(encoded_u8[n])\n",
    "        n += 1\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge([256, 98, 255], (256, 98), 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"SOME UNICODE text with special characters like aÌˆ oÌˆ uÌˆ some emojis ğŸ”¥ and rare unicode\"\n",
    "text = \"aabbabab\"\n",
    "byte_tokens = list(text.encode('utf-8'))\n",
    "original_tokens = byte_tokens.copy()\n",
    "print(byte_tokens)\n",
    "print(len(byte_tokens))\n",
    "merges = []\n",
    "\n",
    "new_token = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('byte_tokens : ', byte_tokens)\n",
    "for merge_no in range(10):\n",
    "    total_tokens_prev = len(byte_tokens)\n",
    "    if total_tokens_prev < 2:\n",
    "        print('maximum merges reached...')\n",
    "        break\n",
    "    most_common_pair = get_most_common_pairs(byte_tokens)\n",
    "    merges.append((new_token, most_common_pair))\n",
    "    byte_tokens = merge(byte_tokens, most_common_pair, new_token)\n",
    "    new_token += 1\n",
    "    print(f'merge : {merge_no + 1} | \\tnew_token : {new_token}')\n",
    "    total_tokens_after = len(byte_tokens)\n",
    "    print(total_tokens_prev, total_tokens_after)\n",
    "    print()\n",
    "    print('byte_tokens : ', byte_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [97, 97, 98, 98, 97, 98, 97, 98]\n",
    "# [97, 255, 98, 255, 255]\n",
    "# [256, 98, 255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_byte_tokens = byte_tokens.copy()\n",
    "reconstruct_tokens = byte_tokens.copy()\n",
    "compressed_byte_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lookup_token, replace_pair in reversed(merges):\n",
    "    # print(lookup_token, replace_pair)\n",
    "    i = 0\n",
    "    temp = []\n",
    "    while i < len(reconstruct_tokens):\n",
    "        current_token = reconstruct_tokens[i]\n",
    "        # print(current_token, lookup_token)\n",
    "        if current_token==lookup_token:\n",
    "            temp.extend(replace_pair)\n",
    "        else:\n",
    "            temp.append(current_token)\n",
    "        i += 1\n",
    "    reconstruct_tokens = temp\n",
    "    print('reconstruct_tokens : ', reconstruct_tokens)\n",
    "\n",
    "# reconstruct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstruct_tokens)\n",
    "print(original_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
